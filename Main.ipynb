{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten,Dense\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "number_of_images = []\n",
    "#load images\n",
    "def load_images_from_folder(folders):\n",
    "    count = 0\n",
    "    for folder in folders:\n",
    "        for filename in os.listdir(folder):\n",
    "            img = cv2.imread(os.path.join(folder,filename))\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img,(256,256))\n",
    "                images.append(img)\n",
    "                count = count + 1\n",
    "        number_of_images.append(count)\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldersname = ['Cobra_Crop/Head','KingCobra_Crop/Head','Krait_Crop/Head']\n",
    "load_images_from_folder(foldersname)\n",
    "\n",
    "X = np.array(images) / 255  #ปรับค่าของตัวแปรให้อยู่ในช่วง 0-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.41176471, 0.36078431, 0.36470588],\n",
       "         [0.41568627, 0.36470588, 0.36470588],\n",
       "         [0.4       , 0.35294118, 0.35294118],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[0.38823529, 0.33333333, 0.3372549 ],\n",
       "         [0.43137255, 0.38431373, 0.38431373],\n",
       "         [0.43529412, 0.38823529, 0.38823529],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[0.4627451 , 0.40784314, 0.41176471],\n",
       "         [0.4       , 0.34117647, 0.34901961],\n",
       "         [0.30196078, 0.25490196, 0.25490196],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.18039216, 0.38431373, 0.31372549],\n",
       "         [0.18039216, 0.38431373, 0.31372549],\n",
       "         [0.23529412, 0.43921569, 0.36862745],\n",
       "         ...,\n",
       "         [0.27058824, 0.42745098, 0.38039216],\n",
       "         [0.27058824, 0.42745098, 0.38039216],\n",
       "         [0.27058824, 0.42745098, 0.38039216]],\n",
       "\n",
       "        [[0.23137255, 0.43137255, 0.36862745],\n",
       "         [0.23137255, 0.43137255, 0.36862745],\n",
       "         [0.25490196, 0.45490196, 0.39215686],\n",
       "         ...,\n",
       "         [0.1372549 , 0.28235294, 0.24705882],\n",
       "         [0.14117647, 0.28627451, 0.24705882],\n",
       "         [0.14117647, 0.28627451, 0.24705882]],\n",
       "\n",
       "        [[0.26666667, 0.45490196, 0.40392157],\n",
       "         [0.26666667, 0.45490196, 0.40392157],\n",
       "         [0.25882353, 0.44313725, 0.39215686],\n",
       "         ...,\n",
       "         [0.05490196, 0.18039216, 0.15686275],\n",
       "         [0.05882353, 0.18431373, 0.16078431],\n",
       "         [0.05882353, 0.18431373, 0.16078431]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.58039216, 0.6627451 , 0.60392157],\n",
       "         [0.58039216, 0.6627451 , 0.60392157],\n",
       "         [0.54901961, 0.63529412, 0.57254902],\n",
       "         ...,\n",
       "         [0.51764706, 0.62352941, 0.55294118],\n",
       "         [0.50588235, 0.61176471, 0.54117647],\n",
       "         [0.50588235, 0.61176471, 0.54117647]],\n",
       "\n",
       "        [[0.58823529, 0.6627451 , 0.61960784],\n",
       "         [0.58823529, 0.6627451 , 0.61960784],\n",
       "         [0.56078431, 0.63921569, 0.59215686],\n",
       "         ...,\n",
       "         [0.37647059, 0.49019608, 0.41568627],\n",
       "         [0.33333333, 0.44705882, 0.37254902],\n",
       "         [0.33333333, 0.44705882, 0.37254902]],\n",
       "\n",
       "        [[0.56862745, 0.64313725, 0.60784314],\n",
       "         [0.56862745, 0.64313725, 0.60784314],\n",
       "         [0.55686275, 0.63529412, 0.59607843],\n",
       "         ...,\n",
       "         [0.23137255, 0.34901961, 0.2745098 ],\n",
       "         [0.15686275, 0.2745098 , 0.2       ],\n",
       "         [0.15686275, 0.2745098 , 0.2       ]]],\n",
       "\n",
       "\n",
       "       [[[0.22745098, 0.25098039, 0.24705882],\n",
       "         [0.23137255, 0.25490196, 0.25098039],\n",
       "         [0.22745098, 0.25098039, 0.24705882],\n",
       "         ...,\n",
       "         [0.40392157, 0.39607843, 0.36470588],\n",
       "         [0.41176471, 0.40392157, 0.37254902],\n",
       "         [0.41176471, 0.4       , 0.38039216]],\n",
       "\n",
       "        [[0.23137255, 0.25490196, 0.25098039],\n",
       "         [0.23137255, 0.25490196, 0.25098039],\n",
       "         [0.22745098, 0.24705882, 0.24705882],\n",
       "         ...,\n",
       "         [0.39607843, 0.38823529, 0.35686275],\n",
       "         [0.40392157, 0.39607843, 0.36470588],\n",
       "         [0.40784314, 0.39607843, 0.37647059]],\n",
       "\n",
       "        [[0.23137255, 0.25490196, 0.25098039],\n",
       "         [0.23137255, 0.25490196, 0.25098039],\n",
       "         [0.22745098, 0.25098039, 0.24313725],\n",
       "         ...,\n",
       "         [0.4       , 0.39215686, 0.36078431],\n",
       "         [0.40784314, 0.4       , 0.36862745],\n",
       "         [0.41568627, 0.40392157, 0.38431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.25882353, 0.24705882, 0.23137255],\n",
       "         [0.25882353, 0.24705882, 0.23137255],\n",
       "         [0.25882353, 0.24705882, 0.22745098],\n",
       "         ...,\n",
       "         [0.36862745, 0.36862745, 0.36862745],\n",
       "         [0.39607843, 0.39607843, 0.39607843],\n",
       "         [0.40784314, 0.40784314, 0.40784314]],\n",
       "\n",
       "        [[0.25882353, 0.24705882, 0.23137255],\n",
       "         [0.25882353, 0.24705882, 0.23137255],\n",
       "         [0.25882353, 0.24705882, 0.22745098],\n",
       "         ...,\n",
       "         [0.43921569, 0.43921569, 0.43921569],\n",
       "         [0.45882353, 0.45882353, 0.45882353],\n",
       "         [0.47843137, 0.47843137, 0.47843137]],\n",
       "\n",
       "        [[0.25882353, 0.24705882, 0.23137255],\n",
       "         [0.2627451 , 0.25098039, 0.23529412],\n",
       "         [0.2627451 , 0.25098039, 0.23137255],\n",
       "         ...,\n",
       "         [0.53333333, 0.53333333, 0.53333333],\n",
       "         [0.57254902, 0.57254902, 0.57254902],\n",
       "         [0.61176471, 0.61176471, 0.61176471]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.09019608, 0.14901961, 0.15686275],\n",
       "         [0.09019608, 0.14901961, 0.15686275],\n",
       "         [0.09019608, 0.14901961, 0.15686275],\n",
       "         ...,\n",
       "         [0.30588235, 0.33333333, 0.32941176],\n",
       "         [0.28627451, 0.31764706, 0.31372549],\n",
       "         [0.28627451, 0.31764706, 0.31372549]],\n",
       "\n",
       "        [[0.09019608, 0.14901961, 0.15686275],\n",
       "         [0.09019608, 0.14901961, 0.15686275],\n",
       "         [0.09019608, 0.14901961, 0.15686275],\n",
       "         ...,\n",
       "         [0.30588235, 0.33333333, 0.32941176],\n",
       "         [0.28627451, 0.31764706, 0.31372549],\n",
       "         [0.28627451, 0.31764706, 0.31372549]],\n",
       "\n",
       "        [[0.09019608, 0.14901961, 0.15686275],\n",
       "         [0.09019608, 0.14901961, 0.15686275],\n",
       "         [0.09019608, 0.14901961, 0.15686275],\n",
       "         ...,\n",
       "         [0.30588235, 0.33333333, 0.32941176],\n",
       "         [0.28627451, 0.31764706, 0.31372549],\n",
       "         [0.28627451, 0.31764706, 0.31372549]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.55294118, 0.8       , 0.81568627],\n",
       "         [0.55294118, 0.8       , 0.81568627],\n",
       "         [0.55294118, 0.8       , 0.81568627],\n",
       "         ...,\n",
       "         [0.04313725, 0.2       , 0.21960784],\n",
       "         [0.04705882, 0.20392157, 0.22352941],\n",
       "         [0.04705882, 0.20392157, 0.22352941]],\n",
       "\n",
       "        [[0.55294118, 0.8       , 0.81568627],\n",
       "         [0.55294118, 0.8       , 0.81568627],\n",
       "         [0.55294118, 0.8       , 0.81568627],\n",
       "         ...,\n",
       "         [0.04313725, 0.2       , 0.21960784],\n",
       "         [0.04705882, 0.20392157, 0.22352941],\n",
       "         [0.04705882, 0.20392157, 0.22352941]],\n",
       "\n",
       "        [[0.55294118, 0.8       , 0.81568627],\n",
       "         [0.55294118, 0.8       , 0.81568627],\n",
       "         [0.55294118, 0.8       , 0.81568627],\n",
       "         ...,\n",
       "         [0.04313725, 0.2       , 0.21960784],\n",
       "         [0.04705882, 0.20392157, 0.22352941],\n",
       "         [0.04705882, 0.20392157, 0.22352941]]],\n",
       "\n",
       "\n",
       "       [[[0.95294118, 0.9372549 , 0.93333333],\n",
       "         [0.95294118, 0.9372549 , 0.93333333],\n",
       "         [0.95294118, 0.9372549 , 0.93333333],\n",
       "         ...,\n",
       "         [0.12941176, 0.10196078, 0.11372549],\n",
       "         [0.11372549, 0.08627451, 0.09803922],\n",
       "         [0.11372549, 0.08627451, 0.09803922]],\n",
       "\n",
       "        [[0.95294118, 0.9372549 , 0.93333333],\n",
       "         [0.95294118, 0.9372549 , 0.93333333],\n",
       "         [0.94901961, 0.9372549 , 0.93333333],\n",
       "         ...,\n",
       "         [0.12941176, 0.10196078, 0.11372549],\n",
       "         [0.11372549, 0.08627451, 0.09803922],\n",
       "         [0.11372549, 0.08627451, 0.09803922]],\n",
       "\n",
       "        [[0.94901961, 0.9372549 , 0.93333333],\n",
       "         [0.94901961, 0.9372549 , 0.93333333],\n",
       "         [0.94901961, 0.93333333, 0.92941176],\n",
       "         ...,\n",
       "         [0.17647059, 0.14901961, 0.16078431],\n",
       "         [0.17254902, 0.14509804, 0.15686275],\n",
       "         [0.17254902, 0.14509804, 0.15686275]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.98039216, 0.9372549 , 0.9372549 ],\n",
       "         [0.98039216, 0.9372549 , 0.9372549 ],\n",
       "         [0.97647059, 0.92941176, 0.92941176],\n",
       "         ...,\n",
       "         [0.99215686, 0.97647059, 0.97254902],\n",
       "         [0.99607843, 0.98039216, 0.97647059],\n",
       "         [0.99607843, 0.98039216, 0.97647059]],\n",
       "\n",
       "        [[0.98431373, 0.9372549 , 0.9372549 ],\n",
       "         [0.98431373, 0.9372549 , 0.9372549 ],\n",
       "         [0.97647059, 0.92941176, 0.92941176],\n",
       "         ...,\n",
       "         [0.99215686, 0.97647059, 0.97254902],\n",
       "         [1.        , 0.98431373, 0.98039216],\n",
       "         [1.        , 0.98431373, 0.98039216]],\n",
       "\n",
       "        [[0.98431373, 0.9372549 , 0.9372549 ],\n",
       "         [0.98431373, 0.9372549 , 0.9372549 ],\n",
       "         [0.97647059, 0.92941176, 0.92941176],\n",
       "         ...,\n",
       "         [0.99215686, 0.97647059, 0.97254902],\n",
       "         [1.        , 0.98431373, 0.98039216],\n",
       "         [1.        , 0.98431373, 0.98039216]]],\n",
       "\n",
       "\n",
       "       [[[0.0627451 , 0.0745098 , 0.10588235],\n",
       "         [0.05882353, 0.07058824, 0.10196078],\n",
       "         [0.05098039, 0.0627451 , 0.09019608],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.00392157],\n",
       "         [0.        , 0.        , 0.00392157],\n",
       "         [0.        , 0.        , 0.00392157]],\n",
       "\n",
       "        [[0.05882353, 0.07058824, 0.10196078],\n",
       "         [0.05490196, 0.06666667, 0.09803922],\n",
       "         [0.05098039, 0.0627451 , 0.09019608],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.00392157],\n",
       "         [0.        , 0.        , 0.00392157],\n",
       "         [0.        , 0.        , 0.00392157]],\n",
       "\n",
       "        [[0.04313725, 0.05490196, 0.0745098 ],\n",
       "         [0.04313725, 0.05490196, 0.0745098 ],\n",
       "         [0.03921569, 0.05098039, 0.07058824],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.20392157, 0.27058824, 0.32156863],\n",
       "         [0.19607843, 0.2627451 , 0.31372549],\n",
       "         [0.18431373, 0.24705882, 0.29803922],\n",
       "         ...,\n",
       "         [0.17647059, 0.2       , 0.23529412],\n",
       "         [0.09019608, 0.09803922, 0.13333333],\n",
       "         [0.03137255, 0.02745098, 0.0627451 ]],\n",
       "\n",
       "        [[0.18039216, 0.23137255, 0.28627451],\n",
       "         [0.16470588, 0.21568627, 0.27058824],\n",
       "         [0.14509804, 0.19215686, 0.24705882],\n",
       "         ...,\n",
       "         [0.16078431, 0.18823529, 0.23137255],\n",
       "         [0.11764706, 0.13333333, 0.17254902],\n",
       "         [0.09019608, 0.09411765, 0.13333333]],\n",
       "\n",
       "        [[0.16078431, 0.19215686, 0.24313725],\n",
       "         [0.14901961, 0.18039216, 0.23137255],\n",
       "         [0.12941176, 0.16078431, 0.21176471],\n",
       "         ...,\n",
       "         [0.10980392, 0.13333333, 0.18431373],\n",
       "         [0.11764706, 0.13333333, 0.18039216],\n",
       "         [0.12941176, 0.1372549 , 0.18039216]]]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#เตรียม output\n",
    "def defined_output(number_of_images):\n",
    "    for count,num in enumerate(number_of_images):\n",
    "        for i in range(num):\n",
    "            classes = len(number_of_images)\n",
    "            output = np.zeros((classes,), dtype=int)\n",
    "            output[count] = 1\n",
    "            y.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "defined_output(number_of_images)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential , Model\n",
    "from tensorflow.keras.layers import Dense , Activation\n",
    "from tensorflow.keras.layers import Dropout , GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD , RMSprop , Adadelta , Adam\n",
    "from tensorflow.keras.layers import Conv2D , BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(256,256,3))\n",
    "\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(model.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1034 (Conv2D)            (None, 127, 127, 32) 864         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1034 (Batch (None, 127, 127, 32) 96          conv2d_1034[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1034 (Activation)    (None, 127, 127, 32) 0           batch_normalization_1034[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1035 (Conv2D)            (None, 125, 125, 32) 9216        activation_1034[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1035 (Batch (None, 125, 125, 32) 96          conv2d_1035[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1035 (Activation)    (None, 125, 125, 32) 0           batch_normalization_1035[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1036 (Conv2D)            (None, 125, 125, 64) 18432       activation_1035[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1036 (Batch (None, 125, 125, 64) 192         conv2d_1036[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1036 (Activation)    (None, 125, 125, 64) 0           batch_normalization_1036[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling2D) (None, 62, 62, 64)   0           activation_1036[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1037 (Conv2D)            (None, 62, 62, 80)   5120        max_pooling2d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1037 (Batch (None, 62, 62, 80)   240         conv2d_1037[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1037 (Activation)    (None, 62, 62, 80)   0           batch_normalization_1037[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1038 (Conv2D)            (None, 60, 60, 192)  138240      activation_1037[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1038 (Batch (None, 60, 60, 192)  576         conv2d_1038[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1038 (Activation)    (None, 60, 60, 192)  0           batch_normalization_1038[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling2D) (None, 29, 29, 192)  0           activation_1038[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1042 (Conv2D)            (None, 29, 29, 64)   12288       max_pooling2d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1042 (Batch (None, 29, 29, 64)   192         conv2d_1042[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1042 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1042[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1040 (Conv2D)            (None, 29, 29, 48)   9216        max_pooling2d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1043 (Conv2D)            (None, 29, 29, 96)   55296       activation_1042[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1040 (Batch (None, 29, 29, 48)   144         conv2d_1040[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1043 (Batch (None, 29, 29, 96)   288         conv2d_1043[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1040 (Activation)    (None, 29, 29, 48)   0           batch_normalization_1040[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1043 (Activation)    (None, 29, 29, 96)   0           batch_normalization_1043[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_99 (AveragePo (None, 29, 29, 192)  0           max_pooling2d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1039 (Conv2D)            (None, 29, 29, 64)   12288       max_pooling2d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1041 (Conv2D)            (None, 29, 29, 64)   76800       activation_1040[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1044 (Conv2D)            (None, 29, 29, 96)   82944       activation_1043[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1045 (Conv2D)            (None, 29, 29, 32)   6144        average_pooling2d_99[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1039 (Batch (None, 29, 29, 64)   192         conv2d_1039[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1041 (Batch (None, 29, 29, 64)   192         conv2d_1041[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1044 (Batch (None, 29, 29, 96)   288         conv2d_1044[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1045 (Batch (None, 29, 29, 32)   96          conv2d_1045[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1039 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1039[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1041 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1041[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1044 (Activation)    (None, 29, 29, 96)   0           batch_normalization_1044[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1045 (Activation)    (None, 29, 29, 32)   0           batch_normalization_1045[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 29, 29, 256)  0           activation_1039[0][0]            \n",
      "                                                                 activation_1041[0][0]            \n",
      "                                                                 activation_1044[0][0]            \n",
      "                                                                 activation_1045[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1049 (Conv2D)            (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1049 (Batch (None, 29, 29, 64)   192         conv2d_1049[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1049 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1049[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1047 (Conv2D)            (None, 29, 29, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1050 (Conv2D)            (None, 29, 29, 96)   55296       activation_1049[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1047 (Batch (None, 29, 29, 48)   144         conv2d_1047[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1050 (Batch (None, 29, 29, 96)   288         conv2d_1050[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1047 (Activation)    (None, 29, 29, 48)   0           batch_normalization_1047[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1050 (Activation)    (None, 29, 29, 96)   0           batch_normalization_1050[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_100 (AverageP (None, 29, 29, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1046 (Conv2D)            (None, 29, 29, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1048 (Conv2D)            (None, 29, 29, 64)   76800       activation_1047[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1051 (Conv2D)            (None, 29, 29, 96)   82944       activation_1050[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1052 (Conv2D)            (None, 29, 29, 64)   16384       average_pooling2d_100[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1046 (Batch (None, 29, 29, 64)   192         conv2d_1046[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1048 (Batch (None, 29, 29, 64)   192         conv2d_1048[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1051 (Batch (None, 29, 29, 96)   288         conv2d_1051[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1052 (Batch (None, 29, 29, 64)   192         conv2d_1052[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1046 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1046[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1048 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1048[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1051 (Activation)    (None, 29, 29, 96)   0           batch_normalization_1051[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1052 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1052[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 29, 29, 288)  0           activation_1046[0][0]            \n",
      "                                                                 activation_1048[0][0]            \n",
      "                                                                 activation_1051[0][0]            \n",
      "                                                                 activation_1052[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1056 (Conv2D)            (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1056 (Batch (None, 29, 29, 64)   192         conv2d_1056[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1056 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1056[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1054 (Conv2D)            (None, 29, 29, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1057 (Conv2D)            (None, 29, 29, 96)   55296       activation_1056[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1054 (Batch (None, 29, 29, 48)   144         conv2d_1054[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1057 (Batch (None, 29, 29, 96)   288         conv2d_1057[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1054 (Activation)    (None, 29, 29, 48)   0           batch_normalization_1054[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1057 (Activation)    (None, 29, 29, 96)   0           batch_normalization_1057[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_101 (AverageP (None, 29, 29, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1053 (Conv2D)            (None, 29, 29, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1055 (Conv2D)            (None, 29, 29, 64)   76800       activation_1054[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1058 (Conv2D)            (None, 29, 29, 96)   82944       activation_1057[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1059 (Conv2D)            (None, 29, 29, 64)   18432       average_pooling2d_101[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1053 (Batch (None, 29, 29, 64)   192         conv2d_1053[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1055 (Batch (None, 29, 29, 64)   192         conv2d_1055[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1058 (Batch (None, 29, 29, 96)   288         conv2d_1058[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1059 (Batch (None, 29, 29, 64)   192         conv2d_1059[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1053 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1053[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1055 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1055[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1058 (Activation)    (None, 29, 29, 96)   0           batch_normalization_1058[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1059 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1059[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 29, 29, 288)  0           activation_1053[0][0]            \n",
      "                                                                 activation_1055[0][0]            \n",
      "                                                                 activation_1058[0][0]            \n",
      "                                                                 activation_1059[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1061 (Conv2D)            (None, 29, 29, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1061 (Batch (None, 29, 29, 64)   192         conv2d_1061[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1061 (Activation)    (None, 29, 29, 64)   0           batch_normalization_1061[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1062 (Conv2D)            (None, 29, 29, 96)   55296       activation_1061[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1062 (Batch (None, 29, 29, 96)   288         conv2d_1062[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1062 (Activation)    (None, 29, 29, 96)   0           batch_normalization_1062[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1060 (Conv2D)            (None, 14, 14, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1063 (Conv2D)            (None, 14, 14, 96)   82944       activation_1062[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1060 (Batch (None, 14, 14, 384)  1152        conv2d_1060[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1063 (Batch (None, 14, 14, 96)   288         conv2d_1063[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1060 (Activation)    (None, 14, 14, 384)  0           batch_normalization_1060[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1063 (Activation)    (None, 14, 14, 96)   0           batch_normalization_1063[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling2D) (None, 14, 14, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 14, 14, 768)  0           activation_1060[0][0]            \n",
      "                                                                 activation_1063[0][0]            \n",
      "                                                                 max_pooling2d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1068 (Conv2D)            (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1068 (Batch (None, 14, 14, 128)  384         conv2d_1068[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1068 (Activation)    (None, 14, 14, 128)  0           batch_normalization_1068[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1069 (Conv2D)            (None, 14, 14, 128)  114688      activation_1068[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1069 (Batch (None, 14, 14, 128)  384         conv2d_1069[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1069 (Activation)    (None, 14, 14, 128)  0           batch_normalization_1069[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1065 (Conv2D)            (None, 14, 14, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1070 (Conv2D)            (None, 14, 14, 128)  114688      activation_1069[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1065 (Batch (None, 14, 14, 128)  384         conv2d_1065[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1070 (Batch (None, 14, 14, 128)  384         conv2d_1070[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1065 (Activation)    (None, 14, 14, 128)  0           batch_normalization_1065[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1070 (Activation)    (None, 14, 14, 128)  0           batch_normalization_1070[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1066 (Conv2D)            (None, 14, 14, 128)  114688      activation_1065[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1071 (Conv2D)            (None, 14, 14, 128)  114688      activation_1070[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1066 (Batch (None, 14, 14, 128)  384         conv2d_1066[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1071 (Batch (None, 14, 14, 128)  384         conv2d_1071[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1066 (Activation)    (None, 14, 14, 128)  0           batch_normalization_1066[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1071 (Activation)    (None, 14, 14, 128)  0           batch_normalization_1071[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_102 (AverageP (None, 14, 14, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1064 (Conv2D)            (None, 14, 14, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1067 (Conv2D)            (None, 14, 14, 192)  172032      activation_1066[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1072 (Conv2D)            (None, 14, 14, 192)  172032      activation_1071[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1073 (Conv2D)            (None, 14, 14, 192)  147456      average_pooling2d_102[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1064 (Batch (None, 14, 14, 192)  576         conv2d_1064[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1067 (Batch (None, 14, 14, 192)  576         conv2d_1067[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1072 (Batch (None, 14, 14, 192)  576         conv2d_1072[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1073 (Batch (None, 14, 14, 192)  576         conv2d_1073[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1064 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1064[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1067 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1067[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1072 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1072[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1073 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1073[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 14, 14, 768)  0           activation_1064[0][0]            \n",
      "                                                                 activation_1067[0][0]            \n",
      "                                                                 activation_1072[0][0]            \n",
      "                                                                 activation_1073[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1078 (Conv2D)            (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1078 (Batch (None, 14, 14, 160)  480         conv2d_1078[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1078 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1078[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1079 (Conv2D)            (None, 14, 14, 160)  179200      activation_1078[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1079 (Batch (None, 14, 14, 160)  480         conv2d_1079[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1079 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1079[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1075 (Conv2D)            (None, 14, 14, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1080 (Conv2D)            (None, 14, 14, 160)  179200      activation_1079[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1075 (Batch (None, 14, 14, 160)  480         conv2d_1075[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1080 (Batch (None, 14, 14, 160)  480         conv2d_1080[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1075 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1075[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1080 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1080[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1076 (Conv2D)            (None, 14, 14, 160)  179200      activation_1075[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1081 (Conv2D)            (None, 14, 14, 160)  179200      activation_1080[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1076 (Batch (None, 14, 14, 160)  480         conv2d_1076[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1081 (Batch (None, 14, 14, 160)  480         conv2d_1081[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1076 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1076[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1081 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1081[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_103 (AverageP (None, 14, 14, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1074 (Conv2D)            (None, 14, 14, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1077 (Conv2D)            (None, 14, 14, 192)  215040      activation_1076[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1082 (Conv2D)            (None, 14, 14, 192)  215040      activation_1081[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1083 (Conv2D)            (None, 14, 14, 192)  147456      average_pooling2d_103[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1074 (Batch (None, 14, 14, 192)  576         conv2d_1074[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1077 (Batch (None, 14, 14, 192)  576         conv2d_1077[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1082 (Batch (None, 14, 14, 192)  576         conv2d_1082[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1083 (Batch (None, 14, 14, 192)  576         conv2d_1083[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1074 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1074[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1077 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1077[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1082 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1082[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1083 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1083[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 14, 14, 768)  0           activation_1074[0][0]            \n",
      "                                                                 activation_1077[0][0]            \n",
      "                                                                 activation_1082[0][0]            \n",
      "                                                                 activation_1083[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1088 (Conv2D)            (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1088 (Batch (None, 14, 14, 160)  480         conv2d_1088[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1088 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1088[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1089 (Conv2D)            (None, 14, 14, 160)  179200      activation_1088[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1089 (Batch (None, 14, 14, 160)  480         conv2d_1089[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1089 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1089[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1085 (Conv2D)            (None, 14, 14, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1090 (Conv2D)            (None, 14, 14, 160)  179200      activation_1089[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1085 (Batch (None, 14, 14, 160)  480         conv2d_1085[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1090 (Batch (None, 14, 14, 160)  480         conv2d_1090[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1085 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1085[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1090 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1090[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1086 (Conv2D)            (None, 14, 14, 160)  179200      activation_1085[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1091 (Conv2D)            (None, 14, 14, 160)  179200      activation_1090[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1086 (Batch (None, 14, 14, 160)  480         conv2d_1086[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1091 (Batch (None, 14, 14, 160)  480         conv2d_1091[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1086 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1086[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1091 (Activation)    (None, 14, 14, 160)  0           batch_normalization_1091[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_104 (AverageP (None, 14, 14, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1084 (Conv2D)            (None, 14, 14, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1087 (Conv2D)            (None, 14, 14, 192)  215040      activation_1086[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1092 (Conv2D)            (None, 14, 14, 192)  215040      activation_1091[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1093 (Conv2D)            (None, 14, 14, 192)  147456      average_pooling2d_104[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1084 (Batch (None, 14, 14, 192)  576         conv2d_1084[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1087 (Batch (None, 14, 14, 192)  576         conv2d_1087[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1092 (Batch (None, 14, 14, 192)  576         conv2d_1092[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1093 (Batch (None, 14, 14, 192)  576         conv2d_1093[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1084 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1084[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1087 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1087[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1092 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1092[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1093 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1093[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 14, 14, 768)  0           activation_1084[0][0]            \n",
      "                                                                 activation_1087[0][0]            \n",
      "                                                                 activation_1092[0][0]            \n",
      "                                                                 activation_1093[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1098 (Conv2D)            (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1098 (Batch (None, 14, 14, 192)  576         conv2d_1098[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1098 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1098[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1099 (Conv2D)            (None, 14, 14, 192)  258048      activation_1098[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1099 (Batch (None, 14, 14, 192)  576         conv2d_1099[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1099 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1099[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1095 (Conv2D)            (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1100 (Conv2D)            (None, 14, 14, 192)  258048      activation_1099[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1095 (Batch (None, 14, 14, 192)  576         conv2d_1095[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1100 (Batch (None, 14, 14, 192)  576         conv2d_1100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1095 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1095[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1100 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1100[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1096 (Conv2D)            (None, 14, 14, 192)  258048      activation_1095[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1101 (Conv2D)            (None, 14, 14, 192)  258048      activation_1100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1096 (Batch (None, 14, 14, 192)  576         conv2d_1096[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1101 (Batch (None, 14, 14, 192)  576         conv2d_1101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1096 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1096[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1101 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1101[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_105 (AverageP (None, 14, 14, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1094 (Conv2D)            (None, 14, 14, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1097 (Conv2D)            (None, 14, 14, 192)  258048      activation_1096[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1102 (Conv2D)            (None, 14, 14, 192)  258048      activation_1101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1103 (Conv2D)            (None, 14, 14, 192)  147456      average_pooling2d_105[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1094 (Batch (None, 14, 14, 192)  576         conv2d_1094[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1097 (Batch (None, 14, 14, 192)  576         conv2d_1097[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1102 (Batch (None, 14, 14, 192)  576         conv2d_1102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1103 (Batch (None, 14, 14, 192)  576         conv2d_1103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1094 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1094[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1097 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1097[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1102 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1102[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1103 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1103[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 14, 14, 768)  0           activation_1094[0][0]            \n",
      "                                                                 activation_1097[0][0]            \n",
      "                                                                 activation_1102[0][0]            \n",
      "                                                                 activation_1103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1106 (Conv2D)            (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1106 (Batch (None, 14, 14, 192)  576         conv2d_1106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1106 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1106[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1107 (Conv2D)            (None, 14, 14, 192)  258048      activation_1106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1107 (Batch (None, 14, 14, 192)  576         conv2d_1107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1107 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1107[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1104 (Conv2D)            (None, 14, 14, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1108 (Conv2D)            (None, 14, 14, 192)  258048      activation_1107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1104 (Batch (None, 14, 14, 192)  576         conv2d_1104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1108 (Batch (None, 14, 14, 192)  576         conv2d_1108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1104 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1104[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1108 (Activation)    (None, 14, 14, 192)  0           batch_normalization_1108[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1105 (Conv2D)            (None, 6, 6, 320)    552960      activation_1104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1109 (Conv2D)            (None, 6, 6, 192)    331776      activation_1108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1105 (Batch (None, 6, 6, 320)    960         conv2d_1105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1109 (Batch (None, 6, 6, 192)    576         conv2d_1109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1105 (Activation)    (None, 6, 6, 320)    0           batch_normalization_1105[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1109 (Activation)    (None, 6, 6, 192)    0           batch_normalization_1109[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling2D) (None, 6, 6, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 6, 6, 1280)   0           activation_1105[0][0]            \n",
      "                                                                 activation_1109[0][0]            \n",
      "                                                                 max_pooling2d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1114 (Conv2D)            (None, 6, 6, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1114 (Batch (None, 6, 6, 448)    1344        conv2d_1114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1114 (Activation)    (None, 6, 6, 448)    0           batch_normalization_1114[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1111 (Conv2D)            (None, 6, 6, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1115 (Conv2D)            (None, 6, 6, 384)    1548288     activation_1114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1111 (Batch (None, 6, 6, 384)    1152        conv2d_1111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1115 (Batch (None, 6, 6, 384)    1152        conv2d_1115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1111 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1111[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1115 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1115[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1112 (Conv2D)            (None, 6, 6, 384)    442368      activation_1111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1113 (Conv2D)            (None, 6, 6, 384)    442368      activation_1111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1116 (Conv2D)            (None, 6, 6, 384)    442368      activation_1115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1117 (Conv2D)            (None, 6, 6, 384)    442368      activation_1115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_106 (AverageP (None, 6, 6, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1110 (Conv2D)            (None, 6, 6, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1112 (Batch (None, 6, 6, 384)    1152        conv2d_1112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1113 (Batch (None, 6, 6, 384)    1152        conv2d_1113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1116 (Batch (None, 6, 6, 384)    1152        conv2d_1116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1117 (Batch (None, 6, 6, 384)    1152        conv2d_1117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1118 (Conv2D)            (None, 6, 6, 192)    245760      average_pooling2d_106[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1110 (Batch (None, 6, 6, 320)    960         conv2d_1110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1112 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1112[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1113 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1113[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1116 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1116[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1117 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1117[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1118 (Batch (None, 6, 6, 192)    576         conv2d_1118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1110 (Activation)    (None, 6, 6, 320)    0           batch_normalization_1110[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 6, 6, 768)    0           activation_1112[0][0]            \n",
      "                                                                 activation_1113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 6, 6, 768)    0           activation_1116[0][0]            \n",
      "                                                                 activation_1117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1118 (Activation)    (None, 6, 6, 192)    0           batch_normalization_1118[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 6, 6, 2048)   0           activation_1110[0][0]            \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_22[0][0]             \n",
      "                                                                 activation_1118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1123 (Conv2D)            (None, 6, 6, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1123 (Batch (None, 6, 6, 448)    1344        conv2d_1123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1123 (Activation)    (None, 6, 6, 448)    0           batch_normalization_1123[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1120 (Conv2D)            (None, 6, 6, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1124 (Conv2D)            (None, 6, 6, 384)    1548288     activation_1123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1120 (Batch (None, 6, 6, 384)    1152        conv2d_1120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1124 (Batch (None, 6, 6, 384)    1152        conv2d_1124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1120 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1120[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1124 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1124[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1121 (Conv2D)            (None, 6, 6, 384)    442368      activation_1120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1122 (Conv2D)            (None, 6, 6, 384)    442368      activation_1120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1125 (Conv2D)            (None, 6, 6, 384)    442368      activation_1124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1126 (Conv2D)            (None, 6, 6, 384)    442368      activation_1124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_107 (AverageP (None, 6, 6, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1119 (Conv2D)            (None, 6, 6, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1121 (Batch (None, 6, 6, 384)    1152        conv2d_1121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1122 (Batch (None, 6, 6, 384)    1152        conv2d_1122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1125 (Batch (None, 6, 6, 384)    1152        conv2d_1125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1126 (Batch (None, 6, 6, 384)    1152        conv2d_1126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1127 (Conv2D)            (None, 6, 6, 192)    393216      average_pooling2d_107[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1119 (Batch (None, 6, 6, 320)    960         conv2d_1119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1121 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1121[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1122 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1122[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1125 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1125[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1126 (Activation)    (None, 6, 6, 384)    0           batch_normalization_1126[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1127 (Batch (None, 6, 6, 192)    576         conv2d_1127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1119 (Activation)    (None, 6, 6, 320)    0           batch_normalization_1119[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 6, 6, 768)    0           activation_1121[0][0]            \n",
      "                                                                 activation_1122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 6, 6, 768)    0           activation_1125[0][0]            \n",
      "                                                                 activation_1126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1127 (Activation)    (None, 6, 6, 192)    0           batch_normalization_1127[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 6, 6, 2048)   0           activation_1119[0][0]            \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_23[0][0]             \n",
      "                                                                 activation_1127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 256)          524544      global_average_pooling2d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 256)          0           dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 256)          65792       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 256)          0           dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 3)            771         dropout_23[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,393,891\n",
      "Trainable params: 22,359,459\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 6s 3s/step - loss: 1.1758 - accuracy: 0.3830 - val_loss: 1.1699 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 5s 3s/step - loss: 1.0187 - accuracy: 0.4894 - val_loss: 1.1299 - val_accuracy: 0.4286\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 5s 3s/step - loss: 0.9268 - accuracy: 0.5957 - val_loss: 1.0838 - val_accuracy: 0.5238\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 5s 3s/step - loss: 0.8088 - accuracy: 0.7021 - val_loss: 1.0544 - val_accuracy: 0.5714\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 5s 3s/step - loss: 0.6750 - accuracy: 0.7660 - val_loss: 1.0179 - val_accuracy: 0.6190\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 5s 3s/step - loss: 0.6117 - accuracy: 0.7234 - val_loss: 0.9877 - val_accuracy: 0.6190\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 5s 3s/step - loss: 0.5756 - accuracy: 0.8085 - val_loss: 0.9644 - val_accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 5s 3s/step - loss: 0.4865 - accuracy: 0.8511 - val_loss: 0.9440 - val_accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 5s 3s/step - loss: 0.4527 - accuracy: 0.9149 - val_loss: 0.9328 - val_accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 5s 3s/step - loss: 0.4187 - accuracy: 0.9149 - val_loss: 0.9277 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ec1dee4c8>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=32,epochs=10,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11226137, 0.7662324 , 0.12150628],\n",
       "       [0.15931398, 0.09075771, 0.7499283 ],\n",
       "       [0.2443828 , 0.36110163, 0.39451563],\n",
       "       [0.30842596, 0.4158101 , 0.2757639 ],\n",
       "       [0.07861356, 0.82118326, 0.1002031 ],\n",
       "       [0.12241904, 0.7610191 , 0.11656182],\n",
       "       [0.1910486 , 0.13418776, 0.6747637 ],\n",
       "       [0.12255186, 0.64259857, 0.2348495 ],\n",
       "       [0.0687211 , 0.78649235, 0.14478646],\n",
       "       [0.23157711, 0.70685655, 0.06156628],\n",
       "       [0.17049037, 0.4594865 , 0.37002313],\n",
       "       [0.21936116, 0.45793688, 0.32270193],\n",
       "       [0.30372128, 0.09143899, 0.60483974],\n",
       "       [0.05392414, 0.09578867, 0.8502872 ],\n",
       "       [0.15735857, 0.08179267, 0.7608487 ],\n",
       "       [0.32863048, 0.38393128, 0.28743824],\n",
       "       [0.10280983, 0.06509719, 0.832093  ],\n",
       "       [0.15973565, 0.62648994, 0.21377444],\n",
       "       [0.15164258, 0.52133155, 0.32702598],\n",
       "       [0.22878228, 0.31678292, 0.45443484],\n",
       "       [0.18721892, 0.06743734, 0.7453438 ],\n",
       "       [0.20820531, 0.56575406, 0.2260406 ],\n",
       "       [0.20318441, 0.12294682, 0.6738688 ],\n",
       "       [0.10196158, 0.08373478, 0.8143037 ],\n",
       "       [0.11249792, 0.5552044 , 0.33229765],\n",
       "       [0.17403705, 0.16834174, 0.65762126],\n",
       "       [0.205104  , 0.4694166 , 0.32547936],\n",
       "       [0.20028678, 0.20977111, 0.58994204],\n",
       "       [0.15892686, 0.41070896, 0.43036422],\n",
       "       [0.22388172, 0.28523585, 0.4908824 ],\n",
       "       [0.38706473, 0.11594959, 0.49698564],\n",
       "       [0.22534084, 0.27772605, 0.49693307],\n",
       "       [0.32524183, 0.12113736, 0.5536208 ],\n",
       "       [0.20670637, 0.59045404, 0.20283961]], dtype=float32)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9013 - accuracy: 0.5882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9012659192085266, 0.5882353186607361]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
